{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An overview of the pandas package\n",
    "\n",
    "pandas is a Python package that supports fast, flexible, and expressive data structures, as well as computing functions for data analysis. The following are some prominent features that pandas supports:\n",
    "\n",
    "- Data structure with labeled axes. This makes the program clean and clear and avoids common errors from misaligned data.\n",
    "\n",
    "- Flexible handling of missing data.\n",
    "\n",
    "- Intelligent label-based slicing, fancy indexing, and subset creation of large datasets.\n",
    "\n",
    "- Powerful arithmetic operations and statistical computations on a custom axis via axis label.\n",
    "\n",
    "- Robust input and output support for loading or saving data from and to files, databases, or HDF5 format.\n",
    "\n",
    "Related to pandas installation, we recommend an easy way, that is to install it as a part of Anaconda, a cross-platform distribution for data analysis and scientific computing. You can refer to the [reference]( http://docs.continuum.io/anaconda/) to download and install the library.\n",
    "\n",
    "After installation, we can use it like other Python packages. Firstly, we have to import the following packages at the beginning of the program:\n",
    "\n",
    "```pandas\n",
    ">>> import pandas as pd\n",
    ">>> import numpy as np\n",
    "```\n",
    "\n",
    "Let's first get acquainted with two of pandas' primary data structures: the Series and the DataFrame. They can handle the majority of use cases in finance, statistic, social science, and many areas of engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Series\n",
    "\n",
    "A Series is a one-dimensional object similar to an array, list, or column in table. Each item in a Series is assigned to an entry in an index:\n",
    "```pandas\n",
    ">>> s1 = pd.Series(np.random.rand(4), index=['a', 'b', 'c', 'd'])\n",
    ">>> s1\n",
    "a    0.6122\n",
    "b    0.98096\n",
    "c    0.3350\n",
    "d    0.7221\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "By default, if no index is passed, it will be created to have values ranging from 0 to N-1, where N is the length of the Series:\n",
    "```pandas\n",
    ">>> s2 = pd.Series(np.random.rand(4))\n",
    ">>> s2\n",
    "0    0.6913\n",
    "1    0.8487\n",
    "2    0.8627\n",
    "3    0.7286\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "We can access the value of a Series by using the index:\n",
    "```pandas\n",
    ">>> s1['c']\n",
    "0.3350\n",
    ">>>s1['c'] = 3.14\n",
    ">>> s1['c', 'a', 'b']\n",
    "c    3.14\n",
    "a    0.6122\n",
    "b    0.98096\n",
    "```\n",
    "\n",
    "This accessing method is similar to a Python dictionary. Therefore, pandas also allows us to initialize a Series object directly from a Python dictionary:\n",
    "\n",
    "```pandas\n",
    ">>> s3 = pd.Series({'001': 'Nam', '002': 'Mary', '003': 'Peter'})\n",
    ">>> s3\n",
    "001    Nam\n",
    "002    Mary\n",
    "003    Peter\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "Sometimes, we want to filter or rename the index of a Series created from a Python dictionary. At such times, we can pass the selected index list directly to the initial function, similarly to the process in the preceding example. Only elements that exist in the index list will be in the Series object. Conversely, indexes that are missing in the dictionary are initialized to default NaN values by pandas:\n",
    "```pandas\n",
    ">>> s4 = pd.Series({'001': 'Nam', '002': 'Mary',\n",
    "                    '003': 'Peter'}, index=[\n",
    "                    '002', '001', '024', '065'])\n",
    ">>> s4\n",
    "002    Mary\n",
    "001    Nam\n",
    "024    NaN\n",
    "065    NaN\n",
    "dtype:   object\n",
    "```\n",
    "\n",
    "The library also supports functions that detect missing data:\n",
    "```pandas\n",
    ">>> pd.isnull(s4)\n",
    "002    False\n",
    "001    False\n",
    "024    True\n",
    "065    True\n",
    "dtype: bool\n",
    "```\n",
    "\n",
    "Similarly, we can also initialize a Series from a scalar value:\n",
    "```pandas\n",
    ">>> s5 = pd.Series(2.71, index=['x', 'y'])\n",
    ">>> s5\n",
    "x    2.71\n",
    "y    2.71\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "A Series object can be initialized with NumPy objects as well, such as ndarray. Moreover, pandas can automatically align data indexed in different ways in arithmetic operations:\n",
    "```pandas\n",
    ">>> s6 = pd.Series(np.array([2.71, 3.14]), index=['z', 'y'])\n",
    ">>> s6\n",
    "z    2.71\n",
    "y    3.14\n",
    "dtype: float64\n",
    "\n",
    ">>> s5 + s6\n",
    "x    NaN\n",
    "y    5.85\n",
    "z    NaN\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The DataFrame\n",
    "\n",
    "The DataFrame is a tabular data structure coprising a set of ordered columns and rows. It can be thought of as a group of Series objects that share an index (the column names). There are a number of ways to initialize a DataFrame object. Firstly, let's take a look at the common example of creating DataFrame from a dictionary of lists:\n",
    "```pandas\n",
    ">>> data = {'Year': [2000, 2005, 2010, 2014],\n",
    "         'Median_Age': [24.2, 26.4, 28.5, 30.3],\n",
    "         'Density': [244, 256, 268, 279]}\n",
    ">>> df1 = pd.DataFrame(data)\n",
    ">>> df1\n",
    "    Density    Median_Age    Year\n",
    "0  244        24.2        2000\n",
    "1  256        26.4        2005\n",
    "2  268        28.5        2010\n",
    "3  279        30.3        2014\n",
    "```\n",
    "\n",
    "By default, the DataFrame constructor will order the column alphabetically. We can edit the default order by passing the column's attribute to the initializing function:\n",
    "```pandas\n",
    ">>> df2 = pd.DataFrame(data, columns=['Year', 'Density', 'Median_Age'])\n",
    ">>> df2\n",
    "    Year    Density    Median_Age\n",
    "0    2000    244        24.2\n",
    "1    2005    256        26.4\n",
    "2    2010    268        28.5\n",
    "3    2014    279        30.3\n",
    "\n",
    ">>> df2.index\n",
    "Int64Index([0, 1, 2, 3], dtype='int64')\n",
    "```\n",
    "\n",
    "We can provide the index labels of a DataFrame similar to a Series:\n",
    "```pandas\n",
    ">>> df3 = pd.DataFrame(data, columns=['Year', 'Density', 'Median_Age'], index=['a', 'b', 'c', 'd'])\n",
    ">>> df3.index\n",
    "Index([u'a', u'b', u'c', u'd'], dtype='object')\n",
    "```\n",
    "\n",
    "We can construct a DataFrame out of nested lists as well:\n",
    "```pandas\n",
    ">>> df4 = pd.DataFrame([\n",
    "    ['Peter', 16, 'pupil', 'TN', 'M', None],\n",
    "    ['Mary', 21, 'student', 'SG', 'F', None],\n",
    "    ['Nam', 22, 'student', 'HN', 'M', None],\n",
    "    ['Mai', 31, 'nurse', 'SG', 'F', None],\n",
    "    ['John', 28, 'laywer', 'SG', 'M', None]],\n",
    "columns=['name', 'age', 'career', 'province', 'sex', 'award'])\n",
    "```\n",
    "\n",
    "Columns can be accessed by column name as a Series can, either by dictionary-like notation or as an attribute, if the column name is a syntactically valid attribute name:\n",
    "```pandas\n",
    ">>> df4.name    # or df4['name'] \n",
    "0    Peter\n",
    "1    Mary\n",
    "2    Nam\n",
    "3    Mai\n",
    "4    John\n",
    "Name: name, dtype: object\n",
    "```\n",
    "\n",
    "To modify or append a new column to the created DataFrame, we specify the column name and the value we want to assign:\n",
    "```pandas\n",
    ">>> df4['award'] = None\n",
    ">>> df4\n",
    "    name age   career province  sex award\n",
    "0  Peter  16    pupil       TN    M  None\n",
    "1   Mary  21  student       SG    F  None\n",
    "2    Nam  22  student       HN    M  None\n",
    "3   Mai   31    nurse       SG    F  None\n",
    "4  John   28    lawer       SG    M  None\n",
    "```\n",
    "\n",
    "Using a couple of methods, rows can be retrieved by position or name:\n",
    "```pandas\n",
    ">>> df4.ix[1]\n",
    "name           Mary\n",
    "age              21\n",
    "career      student\n",
    "province         SG\n",
    "sex               F\n",
    "award          None\n",
    "Name: 1, dtype: object\n",
    "```\n",
    "\n",
    "A DataFrame object can also be created from different data structures such as a list of dictionaries, a dictionary of Series, or a record array. The method to initialize a DataFrame object is similar to the preceding examples.\n",
    "\n",
    "Another common case is to provide a DataFrame with data from a location such as a text file. In this situation, we use the read_csv function that expects the column separator to be a comma, by default. However, we can change that by using the sep parameter:\n",
    "\n",
    "```pandas\n",
    "# person.csv file\n",
    "name,age,career,province,sex\n",
    "Peter,16,pupil,TN,M\n",
    "Mary,21,student,SG,F\n",
    "Nam,22,student,HN,M\n",
    "Mai,31,nurse,SG,F\n",
    "John,28,lawyer,SG,M\n",
    "# loading person.cvs into a DataFrame\n",
    "```\n",
    "\n",
    "```pandas\n",
    ">>> df4 = pd.read_csv('person.csv')\n",
    ">>> df4\n",
    "     name   age   career   province  sex\n",
    "0    Peter    16    pupil       TN       M\n",
    "1    Mary     21    student     SG       F\n",
    "2    Nam      22    student     HN       M\n",
    "3    Mai      31    nurse       SG       F\n",
    "4    John     28    lawyer      SG       M\n",
    "```\n",
    "\n",
    "While reading a data file, we sometimes want to skip a line or an invalid value. As for pandas 0.16.2, read_csv supports over 50 parameters for controlling the loading process. Some common useful parameters are as follows:\n",
    "\n",
    "- sep: This is a delimiter between columns. The default is comma symbol.\n",
    "\n",
    "- dtype: This is a data type for data or columns.\n",
    "\n",
    "- header: This sets row numbers to use as the column names.\n",
    "\n",
    "- skiprows: This skips line numbers to skip at the start of the file.\n",
    "\n",
    "- error_bad_lines: This shows invalid lines (too many fields) that will, by default, cause an exception, such that no DataFrame will be returned. If we set the value of this parameter as false, the bad lines will be skipped.\n",
    "\n",
    "Moreover, pandas also has support for reading and writing a DataFrame directly from or to a database such as the read_frame or write_frame function within the pandas module. We will come back to these methods later in this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reindexing and altering labels\n",
    "\n",
    "Reindex is a critical method in the pandas data structures. It confirms whether the new or modified data satisfies a given set of labels along a particular axis of pandas object.\n",
    "\n",
    "First, let's view a reindex example on a Series object:\n",
    "```python\n",
    ">>> s2.reindex([0, 2, 'b', 3])\n",
    "0    0.6913\n",
    "2    0.8627\n",
    "b    NaN\n",
    "3    0.7286\n",
    "dtype: float64\n",
    "```\n",
    "When reindexed labels do not exist in the data object, a default value of NaN will be automatically assigned to the position; this holds true for the DataFrame case as well:\n",
    "```python\n",
    ">>> df1.reindex(index=[0, 2, 'b', 3], columns=['Density', 'Year', 'Median_Age','C'])\n",
    "   Density  Year  Median_Age        C\n",
    "0      244  2000        24.2      NaN\n",
    "2      268  2010        28.5      NaN\n",
    "b      NaN   NaN         NaN      NaN\n",
    "3      279  2014        30.3      NaN\n",
    "```\n",
    "We can change the NaN value in the missing index case to a custom value by setting the fill_value parameter. Let us take a look at the arguments that the reindex function supports, as shown in the following table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### index\n",
    "This is the new labels/index to conform to.\n",
    "\n",
    "#### method\n",
    "This is the method to use for filling holes in a reindexed object. The default setting is unfill gaps.\n",
    "<pre>\n",
    "pad/ffill: fill values forward\n",
    "backfill/bfill: fill values backward\n",
    "nearest: use the nearest value to fill the gap\n",
    "</pre>\n",
    "\n",
    "#### copy\n",
    "This return a new object. The default setting is true.\n",
    "\n",
    "#### level\n",
    "The matches index values on the passed multiple index level.\n",
    "\n",
    "#### fill_value\n",
    "This is the value to use for missing values. The default setting is NaN.\n",
    "\n",
    "#### limit\n",
    "This is the maximum size gap to fill in forward or backward method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Head and tail\n",
    "\n",
    "In common data analysis situations, our data structure objects contain many columns and a large number of rows. Therefore, we cannot view or load all information of the objects. pandas supports functions that allow us to inspect a small sample. By default, the functions return five elements, but we can set a custom number as well. The following example shows how to display the first five and the last three rows of a longer Series:\n",
    "\n",
    "```python\n",
    ">>> s7 = pd.Series(np.random.rand(10000))\n",
    ">>> s7.head()\n",
    "0    0.631059\n",
    "1    0.766085\n",
    "2    0.066891\n",
    "3    0.867591\n",
    "4    0.339678\n",
    "dtype: float64\n",
    "\n",
    ">>> s7.tail(3)\n",
    "9997    0.412178\n",
    "9998    0.800711\n",
    "9999    0.438344\n",
    "dtype: float64\n",
    "```\n",
    "We can also use these functions for DataFrame objects in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Binary operations\n",
    "\n",
    "Firstly, we will consider arithmetic operations between objects. In different indexes objects case, the expected result will be the union of the index pairs. We will not explain this again because we had an example about it in the previous section (s5 + s6). This time, we will show another example with a DataFrame:\n",
    "```python\n",
    ">>> df5 = pd.DataFrame(np.arange(9).reshape(3,3), columns=['a','b','c'])\n",
    ">>> df5\n",
    "   a  b  c\n",
    "0  0  1  2\n",
    "1  3  4  5\n",
    "2  6  7  8\n",
    "\n",
    ">>> df6 = pd.DataFrame(np.arange(8).reshape(2,4), columns=['a','b','c','d'])\n",
    ">>> df6\n",
    "   a  b  c  d\n",
    "0  0  1  2  3\n",
    "1  4  5  6  7\n",
    "\n",
    ">>> df5 + df6\n",
    "    a   b   c   d\n",
    "0   0   2   4 NaN\n",
    "1   7   9  11 NaN\n",
    "2   NaN NaN NaN NaN\n",
    "```\n",
    "\n",
    "The mechanisms for returning the result between two kinds of data structure are similar. A problem that we need to consider is the missing data between objects. In this case, if we want to fill with a fixed value, such as 0, we can use the arithmetic functions such as add, sub, div, and mul, and the function's supported parameters such as fill_value:\n",
    "```python\n",
    ">>> df7 = df5.add(df6, fill_value=0)\n",
    ">>> df7\n",
    "   a  b   c   d\n",
    "0  0  2   4   3\n",
    "1  7  9  11   7\n",
    "2  6  7   8   NaN\n",
    "```\n",
    "\n",
    "Next, we will discuss comparison operations between data objects. We have some supported functions such as equal (eq), not equal (ne), greater than (gt), less than (lt), less equal (le), and greater equal (ge). Here is an example:\n",
    "```python\n",
    ">>> df5.eq(df6)\n",
    "       a      b      c      d\n",
    "0   True   True   True  False\n",
    "1  False  False  False  False\n",
    "2  False  False  False  False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Functional statistics\n",
    "\n",
    "The supported statistics method of a library is really important in data analysis. To get inside a big data object, we need to know some summarized information such as mean, sum, or quantile. pandas supports a large number of methods to compute them. Let's consider a simple example of calculating the sum information of df5, which is a DataFrame object:\n",
    "```python\n",
    ">>> df5.sum()\n",
    "a     9\n",
    "b    12\n",
    "c    15\n",
    "dtype: int64\n",
    "```\n",
    "When we do not specify which axis we want to calculate sum information, by default, the function will calculate on index axis, which is axis 0:\n",
    "\n",
    "- Series: We do not need to specify the axis.\n",
    "\n",
    "- DataFrame: Columns (axis = 1) or index (axis = 0). The default setting is axis 0.\n",
    "\n",
    "We also have the skipna parameter that allows us to decide whether to exclude missing data or not. By default, it is set as true:\n",
    "```python\n",
    ">>> df7.sum(skipna=False)\n",
    "a    13\n",
    "b    18\n",
    "c    23\n",
    "d   NaN\n",
    "dtype: float64\n",
    "```\n",
    "Another function that we want to consider is describe(). It is very convenient for us to summarize most of the statistical information of a data structure such as the Series and DataFrame, as well:\n",
    "```python\n",
    ">>> df5.describe()\n",
    "         a    b    c\n",
    "count  3.0  3.0  3.0\n",
    "mean   3.0  4.0  5.0\n",
    "std    3.0  3.0  3.0\n",
    "min    0.0  1.0  2.0\n",
    "25%    1.5  2.5  3.5\n",
    "50%    3.0  4.0  5.0\n",
    "75%    4.5  5.5  6.5\n",
    "max    6.0  7.0  8.0\n",
    "```\n",
    "We can specify percentiles to include or exclude in the output by using the percentiles parameter; for example, consider the following:\n",
    "```python\n",
    ">>> df5.describe(percentiles=[0.5, 0.8])\n",
    "         a    b    c\n",
    "count  3.0  3.0  3.0\n",
    "mean   3.0  4.0  5.0\n",
    "std    3.0  3.0  3.0\n",
    "min    0.0  1.0  2.0\n",
    "50%    3.0  4.0  5.0\n",
    "80%    4.8  5.8  6.8\n",
    "max    6.0  7.0  8.0\n",
    "```\n",
    "Here, we have a summary table for common supported statistics functions in pandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>idxmin(axis), idxmax(axis)</b>: This compute the index labels with the minimum or maximum corresponding values.\n",
    "- <b>value_counts()</b>: This compute the frequency of unique values.\n",
    "- <b>count()</b>: This return the number of non-null values in a data object.\n",
    "- <b>mean(), median(), min(), max()</b>: This return mean, median, minimum, and maximum values of an axis in a data object.\n",
    "- <b>std(), var(), sem()</b>: These return the standard deviation, variance, and standard error of mean.\n",
    "- <b>abs()</b>: This gets the absolute value of a data object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Function application\n",
    "\n",
    "pandas supports function application that allows us to apply some functions supported in other packages such as NumPy or our own functions on data structure objects. Here, we illustrate two examples of these cases, firstly, using apply to execute the std() function, which is the standard deviation calculating function of the NumPy package:\n",
    "```python\n",
    ">>> df5.apply(np.std, axis=1)    # default: axis=0\n",
    "0    0.816497\n",
    "1    0.816497\n",
    "2    0.816497\n",
    "dtype: float64\n",
    "```\n",
    "Secondly, if we want to apply a formula to a data object, we can also use apply function by following these steps:\n",
    "\n",
    "Define the function or formula that you want to apply on a data object.\n",
    "\n",
    "Call the defined function or formula via apply. In this step, we also need to figure out the axis that we want to apply the calculation to:\n",
    "\n",
    "```python\n",
    ">>> f = lambda x: x.max() â€“ x.min()    # step 1\n",
    ">>> df5.apply(f, axis=1)               # step 2\n",
    "0    2\n",
    "1    2\n",
    "2    2\n",
    "dtype: int64\n",
    "\n",
    ">>> def sigmoid(x):\n",
    "        return 1/(1 + np.exp(x))\n",
    "        \n",
    ">>> df5.apply(sigmoid)\n",
    "     a           b         c\n",
    "0  0.500000  0.268941  0.119203\n",
    "1  0.047426  0.017986  0.006693\n",
    "2  0.002473  0.000911  0.000335\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Sorting\n",
    "\n",
    "There are two kinds of sorting method that we are interested in: sorting by row or column index and sorting by data value.\n",
    "\n",
    "Firstly, we will consider methods for sorting by row and column index. In this case, we have the sort_index() function. We also have axis parameter to set whether the function should sort by row or column. The ascending option with the true or false value will allow us to sort data in ascending or descending order. The default setting for this option is true:\n",
    "\n",
    "```python\n",
    ">>> df7 = pd.DataFrame(np.arange(12).reshape(3,4),  \n",
    "                       columns=['b', 'd', 'a', 'c'],\n",
    "                       index=['x', 'y', 'z'])\n",
    ">>> df7\n",
    "   b  d   a   c\n",
    "x  0  1   2   3\n",
    "y  4  5   6   7\n",
    "z  8  9  10  11\n",
    "\n",
    ">>> df7.sort_index(axis=1)\n",
    "    a  b   c  d\n",
    "x   2  0   3  1\n",
    "y   6  4   7  5\n",
    "z  10  8  11  9\n",
    "```\n",
    "Series has a method order that sorts by value. For NaN values in the object, we can also have a special treatment via the na_position option:\n",
    "\n",
    "```python\n",
    ">>> s4.order(na_position='first')\n",
    "024     NaN\n",
    "065     NaN\n",
    "002    Mary\n",
    "001     Nam\n",
    "dtype: object\n",
    "\n",
    ">>> s4\n",
    "002    Mary\n",
    "001     Nam\n",
    "024     NaN\n",
    "065     NaN\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "Besides that, Series also has the sort() function that sorts data by value. However, the function will not return a copy of the sorted data:\n",
    "```python\n",
    ">>> s4.sort(na_position='first')\n",
    ">>> s4\n",
    "024     NaN\n",
    "065     NaN\n",
    "002    Mary\n",
    "001     Nam\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "If we want to apply sort function to a DataFrame object, we need to figure out which columns or rows will be sorted:\n",
    "\n",
    "```python\n",
    ">>> df7.sort(['b', 'd'], ascending=False)\n",
    "   b  d   a   c\n",
    "z  8  9  10  11\n",
    "y  4  5   6   7\n",
    "x  0  1   2   3\n",
    "```\n",
    "If we do not want to automatically save the sorting result to the current data object, we can change the setting of the inplace parameter to False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Indexing and selecting data\n",
    "\n",
    "In this section, we will focus on how to get, set, or slice subsets of pandas data structure objects. As we learned in previous sections, Series or DataFrame objects have axis labeling information. This information can be used to identify items that we want to select or assign a new value to in the object:\n",
    "```pandas\n",
    ">>> s4[['024', '002']]    # selecting data of Series object\n",
    "024     NaN\n",
    "002    Mary\n",
    "dtype: object\n",
    ">>> s4[['024', '002']] = 'unknown' # assigning data\n",
    ">>> s4\n",
    "024    unknown\n",
    "065        NaN\n",
    "002    unknown\n",
    "001        Nam\n",
    "dtype: object\n",
    "```\n",
    "If the data object is a DataFrame structure, we can also proceed in a similar way:\n",
    "```pandas\n",
    ">>> df5[['b', 'c']]\n",
    "   b  c\n",
    "0  1  2\n",
    "1  4  5\n",
    "2  7  8\n",
    "```\n",
    "For label indexing on the rows of DataFrame, we use the ix function that enables us to select a set of rows and columns in the object. There are two parameters that we need to specify: the row and column labels that we want to get. By default, if we do not specify the selected column names, the function will return selected rows with all columns in the object:\n",
    "```pandas\n",
    ">>> df5.ix[0]\n",
    "a    0\n",
    "b    1\n",
    "c    2\n",
    "Name: 0, dtype: int64\n",
    ">>> df5.ix[0, 1:3]\n",
    "b    1\n",
    "c    2\n",
    "Name: 0, dtype: int64\n",
    "```\n",
    "Moreover, we have many ways to select and edit data contained in a pandas object. We summarize these functions in the following table:\n",
    "\n",
    "\n",
    "<b>icol, irow</b>: This selects a single row or column by integer location.\n",
    "\n",
    "<b>get_value, set_value</b>: This selects or sets a single value of a data object by row or column label.\n",
    "\n",
    "<b>xs</b>: This selects a single column or row as a Series by label.\n",
    "\n",
    "<b>Note</b>: pandas data objects may contain duplicate indices. In this case, when we get or set a data value via index label, it will affect all rows or columns that have the same selected index name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Computational tools\n",
    "\n",
    "Let's start with correlation and covariance computation between two data objects. Both the Series and DataFrame have a cov method. On a DataFrame object, this method will compute the covariance between the Series inside the object:\n",
    "```python\n",
    ">>> s1 = pd.Series(np.random.rand(3))\n",
    ">>> s1\n",
    "0    0.460324\n",
    "1    0.993279\n",
    "2    0.032957\n",
    "dtype: float64\n",
    ">>> s2 = pd.Series(np.random.rand(3))\n",
    ">>> s2\n",
    "0    0.777509\n",
    "1    0.573716\n",
    "2    0.664212\n",
    "dtype: float64\n",
    ">>> s1.cov(s2)\n",
    "-0.024516360159045424\n",
    "\n",
    ">>> df8 = pd.DataFrame(np.random.rand(12).reshape(4,3),  \n",
    "                       columns=['a','b','c'])\n",
    ">>> df8\n",
    "          a         b         c\n",
    "0  0.200049  0.070034  0.978615\n",
    "1  0.293063  0.609812  0.788773\n",
    "2  0.853431  0.243656  0.978057\n",
    "0.985584  0.500765  0.481180\n",
    ">>> df8.cov()\n",
    "          a         b         c\n",
    "a  0.155307  0.021273 -0.048449\n",
    "b  0.021273  0.059925 -0.040029\n",
    "c -0.048449 -0.040029  0.055067\n",
    "```\n",
    "\n",
    "Usage of the correlation method is similar to the covariance method. It computes the correlation between Series inside a data object in case the data object is a DataFrame. However, we need to specify which method will be used to compute the correlations. The available methods are pearson, kendall, and spearman. By default, the function applies the spearman method:\n",
    "```python\n",
    ">>> df8.corr(method = 'spearman')\n",
    "     a    b    c\n",
    "a  1.0  0.4 -0.8\n",
    "b  0.4  1.0 -0.8\n",
    "c -0.8 -0.8  1.0\n",
    "```\n",
    "We also have the corrwith function that supports calculating correlations between Series that have the same label contained in different DataFrame objects:\n",
    "```python\n",
    ">>> df9 = pd.DataFrame(np.arange(8).reshape(4,2), \n",
    "                       columns=['a', 'b'])\n",
    ">>> df9\n",
    "   a  b\n",
    "0  0  1\n",
    "1  2  3\n",
    "2  4  5\n",
    "3  6  7\n",
    ">>> df8.corrwith(df9)\n",
    "a    0.955567\n",
    "b    0.488370\n",
    "c         NaN\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Working with missing data\n",
    "\n",
    "In this section, we will discuss missing, NaN, or null values, in pandas data structures. It is a very common situation to arrive with missing data in an object. One such case that creates missing data is reindexing:\n",
    "```python\n",
    ">>> df8 = pd.DataFrame(np.arange(12).reshape(4,3),  \n",
    "                       columns=['a', 'b', 'c'])\n",
    "   a   b   c\n",
    "0  0   1   2\n",
    "1  3   4   5\n",
    "2  6   7   8\n",
    "3  9  10  11\n",
    "\n",
    ">>> df9 = df8.reindex(columns = ['a', 'b', 'c', 'd'])\n",
    "   a   b   c   d\n",
    "0  0   1   2 NaN\n",
    "1  3   4   5 NaN\n",
    "2  6   7   8 NaN\n",
    "4  9  10  11 NaN\n",
    "\n",
    ">>> df10 = df8.reindex([3, 2, 'a', 0])\n",
    "    a   b   c\n",
    "3   9  10  11\n",
    "2   6   7   8\n",
    "a NaN NaN NaN\n",
    "0   0   1   2\n",
    "```\n",
    "To manipulate missing values, we can use the isnull() or notnull() functions to detect the missing values in a Series object, as well as in a DataFrame object:\n",
    "```python\n",
    ">>> df10.isnull()\n",
    "       a      b      c\n",
    "3  False  False  False\n",
    "2  False  False  False\n",
    "a   True   True   True\n",
    "0  False  False  False\n",
    "```\n",
    "On a Series, we can drop all null data and index values by using the dropna function:\n",
    "```python\n",
    ">>> s4 = pd.Series({'001': 'Nam', '002': 'Mary',\n",
    "                    '003': 'Peter'},\n",
    "                    index=['002', '001', '024', '065'])\n",
    ">>> s4\n",
    "002    Mary\n",
    "001     Nam\n",
    "024     NaN\n",
    "065     NaN\n",
    "dtype: object\n",
    "\n",
    ">>> s4.dropna()    # dropping all null value of Series object\n",
    "002    Mary\n",
    "001     Nam\n",
    "dtype: object\n",
    "```\n",
    "With a DataFrame object, it is a little bit more complex than with Series. We can tell which rows or columns we want to drop and also if all entries must be null or a single null value is enough. By default, the function will drop any row containing a missing value:\n",
    "```python\n",
    ">>> df9.dropna()    # all rows will be dropped\n",
    "Empty DataFrame\n",
    "Columns: [a, b, c, d]\n",
    "Index: []\n",
    "\n",
    ">>> df9.dropna(axis=1)\n",
    "   a   b   c\n",
    "0  0   1   2\n",
    "1  3   4   5\n",
    "2  6   7   8\n",
    "3  9  10  11\n",
    "```\n",
    "Another way to control missing values is to use the supported parameters of functions that we introduced in the previous section. They are also very useful to solve this problem. In our experience, we should assign a fixed value in missing cases when we create data objects. This will make our objects cleaner in later processing steps. For example, consider the following:\n",
    "```python\n",
    ">>> df11 = df8.reindex([3, 2, 'a', 0], fill_value = 0)\n",
    ">>> df11\n",
    "   a   b   c\n",
    "3  9  10  11\n",
    "2  6   7   8\n",
    "a  0   0   0\n",
    "0  0   1   2\n",
    "```\n",
    "We can alse use the fillna function to fill a custom value in missing values:\n",
    "```python\n",
    ">>> df9.fillna(-1)\n",
    "   a   b   c  d\n",
    "0  0   1   2 -1\n",
    "1  3   4   5 -1\n",
    "2  6   7   8 -1\n",
    "3  9  10  11 -1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Hierarchical indexing\n",
    "\n",
    "Hierarchical indexing provides us with a way to work with higher dimensional data in a lower dimension by structuring the data object into multiple index levels on an axis:\n",
    "\n",
    "```python\n",
    ">>> s8 = pd.Series(np.random.rand(8), index=[['a','a','b','b','c','c', 'd','d'], [0, 1, 0, 1, 0,1, 0, 1, ]])\n",
    ">>> s8\n",
    "a  0    0.721652\n",
    "   1    0.297784\n",
    "b  0    0.271995\n",
    "   1    0.125342\n",
    "c  0    0.444074\n",
    "   1    0.948363\n",
    "d  0    0.197565\n",
    "   1    0.883776\n",
    "dtype: float64\n",
    "```\n",
    "In the preceding example, we have a Series object that has two index levels. The object can be rearranged into a DataFrame using the unstack function. In an inverse situation, the stack function can be used:\n",
    "```python\n",
    ">>> s8.unstack()\n",
    "          0         1\n",
    "a  0.549211  0.420874\n",
    "b  0.051516  0.715021\n",
    "c  0.503072  0.720772\n",
    "d  0.373037  0.207026\n",
    "```\n",
    "We can also create a DataFrame to have a hierarchical index in both axes:\n",
    "```python\n",
    ">>> df = pd.DataFrame(np.random.rand(12).reshape(4,3), index=[['a', 'a', 'b', 'b'], [0, 1, 0, 1]],\n",
    "                      columns=[['x', 'x', 'y'], [0, 1, 0]])\n",
    ">>> df\n",
    "            x                   y\n",
    "            0         1         0\n",
    "a 0  0.636893  0.729521  0.747230\n",
    "  1  0.749002  0.323388  0.259496\n",
    "b 0  0.214046  0.926961  0.679686\n",
    "  1  0.013258  0.416101  0.626927\n",
    "\n",
    ">>> df.index\n",
    "MultiIndex(levels=[['a', 'b'], [0, 1]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n",
    "\n",
    ">>> df.columns\n",
    "MultiIndex(levels=[['x', 'y'], [0, 1]], labels=[[0, 0, 1], [0, 1, 0]])\n",
    "```\n",
    "\n",
    "The methods for getting or setting values or subsets of the data objects with multiple index levels are similar to those of the nonhierarchical case:\n",
    "```python\n",
    ">>> df['x']\n",
    "            0         1\n",
    "a 0  0.636893  0.729521\n",
    "  1  0.749002  0.323388\n",
    "b 0  0.214046  0.926961\n",
    "  1  0.013258  0.416101\n",
    "\n",
    ">>> df[[0]]\n",
    "            x\n",
    "            0\n",
    "a 0  0.636893\n",
    "  1  0.749002\n",
    "b 0  0.214046\n",
    "  1  0.013258\n",
    "\n",
    ">>> df.ix['a', 'x']\n",
    "          0         1\n",
    "0  0.636893  0.729521\n",
    "1  0.749002  0.323388\n",
    "\n",
    ">>> df.ix['a','x'].ix[1]\n",
    "0    0.749002\n",
    "1    0.323388\n",
    "Name: 1, dtype: float64\n",
    "```\n",
    "After grouping data into multiple index levels, we can also use most of the descriptive and statistics functions that have a level option, which can be used to specify the level we want to process:\n",
    "```python\n",
    ">>> df.std(level=1)\n",
    "          x                   y\n",
    "          0         1         0\n",
    "0  0.298998  0.139611  0.047761\n",
    "0.520250  0.065558  0.259813\n",
    ">>> df.std(level=0)\n",
    "          x                   y\n",
    "          0         1         0\n",
    "a  0.079273  0.287180  0.344880\n",
    "b  0.141979  0.361232  0.037306\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. The Panel data\n",
    "\n",
    "The Panel is another data structure for three-dimensional data in pandas. However, it is less frequently used than the Series or the DataFrame. You can think of a Panel as a table of DataFrame objects. We can create a Panel object from a 3D ndarray or a dictionary of DataFrame objects:\n",
    "\n",
    "```python\n",
    "# create a Panel from 3D ndarray\n",
    ">>> panel = pd.Panel(np.random.rand(2, 4, 5), items = ['item1', 'item2'])\n",
    ">>> panel\n",
    "<class 'pandas.core.panel.Panel'>\n",
    "Dimensions: 2 (items) x 4 (major_axis) x 5 (minor_axis)\n",
    "Items axis: item1 to item2\n",
    "Major_axis axis: 0 to 3\n",
    "Minor_axis axis: 0 to 4\n",
    "\n",
    ">>> df1 = pd.DataFrame(np.arange(12).reshape(4, 3), columns=['a','b','c'])\n",
    ">>> df1\n",
    "   a   b   c\n",
    "0  0   1   2\n",
    "1  3   4   5\n",
    "2  6   7   8\n",
    "3  9  10  11\n",
    "\n",
    ">>> df2 = pd.DataFrame(np.arange(9).reshape(3, 3), columns=['a','b','c'])\n",
    ">>> df2\n",
    "   a  b  c\n",
    "0  0  1  2\n",
    "1  3  4  5\n",
    "2  6  7  8\n",
    "\n",
    "# create another Panel from a dict of DataFrame objects\n",
    ">>> panel2 = pd.Panel({'item1': df1, 'item2': df2})\n",
    ">>> panel2\n",
    "<class 'pandas.core.panel.Panel'>\n",
    "Dimensions: 2 (items) x 4 (major_axis) x 3 (minor_axis)\n",
    "Items axis: item1 to item2\n",
    "Major_axis axis: 0 to 3\n",
    "Minor_axis axis: a to c\n",
    "```\n",
    "\n",
    "Each item in a Panel is a DataFrame. We can select an item, by item name:\n",
    "```python\n",
    ">>> panel2['item1']\n",
    "   a   b   c\n",
    "0  0   1   2\n",
    "1  3   4   5\n",
    "2  6   7   8\n",
    "3  9  10  11\n",
    "```\n",
    "Alternatively, if we want to select data via an axis or data position, we can use the ix method, like on Series or DataFrame:\n",
    "```python\n",
    ">>> panel2.ix[:, 1:3, ['b', 'c']]\n",
    "<class 'pandas.core.panel.Panel'>\n",
    "Dimensions: 2 (items) x 3 (major_axis) x 2 (minor_axis)\n",
    "Items axis: item1 to item2\n",
    "Major_axis axis: 1 to 3\n",
    "Minor_axis axis: b to c\n",
    ">>> panel2.ix[:, 2, :]\n",
    "   item1  item2\n",
    "a      6      6\n",
    "b      7      7\n",
    "c      8      8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
